<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="IEG">
  <meta name="keywords" content="IEG">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HG-SCRUB</title>

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/index_2.js"></script>

  <style>
    .section-divider {
      width: 100%;
      margin: 20px auto;
      height: 2px;
      background-color: #e0e0e0;
      border: none;
    }
    figure {
      text-align: center;
    }
    figcaption {
      font-size: 0.9em;
      color: #555;
    }
    section:nth-child(even) {
      background-color: #f9f9f9;
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="#">HG-SCRUB</a>
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">HG-SCRUB: Human Gaussian Single Camera Relighting with Unified Blending</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="">Junsuk (John) Kim</a><sup>1</sup>,</span>
            <span class="author-block"><a href="">Neil Gautam</a><sup>1</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Texas A&M University - College Station</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            HG-SCRUB presents a lightweight solution for relighting and blending human avatars from monocular video input into new environments. By leveraging 3D Gaussian Splatting, inverse rendering, and learned environment maps, our method achieves physically consistent integration and visual realism, even under novel lighting.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr class="section-divider">
        <h2 class="title is-4">[Relighting & Blending Examples]</h2>
      </div>
    </div>
    <div id="carousel-relighting" class="carousel">
      <div class="carousel-item">
        <figure>
          <img src="https://huggingface.co/datasets/johnkimryno/HG-SCRUB/resolve/main/dragon_bed.gif">
          <figcaption>Relighting in Bedroom Scene</figcaption>
        </figure>
      </div>
      <div class="carousel-item">
        <figure>
          <img src="https://huggingface.co/datasets/johnkimryno/HG-SCRUB/resolve/main/dragon_lab_relight.gif">
          <figcaption>Relighting in Lab Scene</figcaption>
        </figure>
      </div>
    </div>
    <script>
      document.addEventListener('DOMContentLoaded', () => {
        bulmaCarousel.attach('#carousel-relighting', {
          slidesToScroll: 1,
          slidesToShow: 1,
          loop: true,
          autoplay: true,
          autoplaySpeed: 3000,
        });
      });
    </script>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr class="section-divider">
        <h2 class="title is-4">[Previous Work]</h2>
        <div class="content has-text-justified">
          <ul>
            <li><b>HUGS</b>: Used 3D Gaussian Splatting for human reconstruction; lacked lighting and scene-awareness.</li>
            <li><b>The Relightables</b>: High-quality relighting from multi-camera rigs; impractical for everyday use.</li>
            <li><b>PhysAvatar</b>: Added physical interactions; required detailed sensing infrastructure.</li>
            <li><b>GS-IR</b>: Extracted inverse rendering properties (normal, albedo, roughness).</li>
            <li><b>DiffusionLight</b>: Generated environment maps from chrome ball cues.</li>
            <li><b>BiGS</b>: Developed relightable Gaussian primitives.</li>
            <li><b>SuGaR</b>: Improved geometry alignment of Gaussians to surfaces—key for contact realism.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr class="section-divider">
        <h2 class="title is-4">[Description of Work]</h2>
        <div class="content has-text-justified">
          <ul>
            <li>Constructed a full pipeline accepting monocular video and a target scene image.</li>
            <li>Reconstructed 3D human Gaussian splats in both canonical and posed space using LBS (Linear Blend Skinning).</li>
            <li>Applied GS-IR and DiffusionLight to extract and learn environment lighting and material maps.</li>
            <li>Extracted {Normal, Albedo, Roughness, Metallic} from both human and target scenes.</li>
            <li>Performed early-stage relighting using both learned environment maps and external chromeball references.</li>
            <li>Developed routines for unifying the human and scene Gaussians with matched geometry and materials.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr class="section-divider">
        <h2 class="title is-4">[Results]</h2>
        <div class="content has-text-justified">
          <ul>
            <li>Achieved relit human Gaussians that respond to target scene lighting.</li>
            <li>Successfully decomposed both the human and scene into physical components (N, A, R, M).</li>
            <li>Performed visual relighting with DiffusionLight and GS-IR.</li>
            <li>Preliminary blended renderings show promise but require refinement.</li>
            <li>Analyzed normal maps for both canonical and posed human reconstructions.</li>
            <li>Completed 3DGS training up to 15,000 iterations, showing convergence in both human and scene representations.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr class="section-divider">
        <h2 class="title is-4">[Analysis of Work]</h2>
        <div class="content has-text-justified">
          <p><strong>New Results:</strong></p>
          <ul>
            <li>Demonstrated a single-camera pipeline for scene-aware avatar relighting and early blending—previously only possible with multi-camera setups.</li>
            <li>Integrated GS-IR with 3D Gaussian Splatting for both human and environment representations.</li>
            <li>Used diffusion-based light probes for real-time environment estimation—this cross-method integration is novel.</li>
          </ul>
          <p><strong>Meeting Goals:</strong></p>
          <ul>
            <li>Partially met: strong relighting achieved, blending still under development.</li>
            <li>Human-scene contact constraints (e.g. floating artifacts) remain uncorrected.</li>
            <li>Geometry-aware alignment needs improvement for SMPL-to-scene surface fidelity.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr class="section-divider">
        <h2 class="title is-4">[Future Work]</h2>
        <div class="content has-text-justified">
          <p><strong>Short-term:</strong></p>
          <ul>
            <li>Finalize unified blending of the human Gaussian with the scene Gaussian.</li>
            <li>Improve SMPL-guided contact fidelity to reduce float artifacts.</li>
            <li>Fine-tune material and lighting extraction with more stable inverse rendering techniques.</li>
          </ul>
          <p><strong>Long-term:</strong></p>
          <ul>
            <li>Introduce temporal consistency constraints across video frames.</li>
            <li>Generalize pipeline to moving backgrounds or outdoor scenes.</li>
            <li>Explore real-time adaptation using lightweight models for AR applications.</li>
          </ul>
          <figure>
            <img src="https://huggingface.co/datasets/johnkimryno/HG-SCRUB/resolve/main/sugar.gif">
            <figcaption>Planned integration with surface-aware alignment (SuGaR inspired)</figcaption>
          </figure>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Empty content removed -->
  </div>
</section>

<footer class="footer">
<div class="container">
<div class="columns is-centered">
  <div class="column is-8">
    <div class="content">
      <p>
        This website is based on <a href="https://nerfies.github.io/">Nerfies</a>, which is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
    </div>
  </div>
</div>
</div>
</footer>





</body>
</html>
